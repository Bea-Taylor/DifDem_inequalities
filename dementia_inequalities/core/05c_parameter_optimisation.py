# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/core/05c_optimise_function.ipynb.

# %% auto 0
__all__ = ['df_dem_plus', 'covar', 'x', 'y', 'result', 'MLE_params', 'MLE_intercept', 'MLE_beta', 'MLE_mu', 'MLE_sigma',
           'reverse_shift_log_normal_pdf', 'log_norm_mode', 'log_rvs_shift_log_normal', 'neg_loglike']

# %% ../../nbs/core/05c_optimise_function.ipynb 3
import autograd.numpy as np
from autograd import grad, jacobian, hessian
from scipy.optimize import minimize
import scipy.stats as stat
import pandas as pd
from matplotlib import pyplot as plt
import matplotlib.font_manager as fm

from fastcore.test import *

from .. import const, log, utils, tools 

# %% ../../nbs/core/05c_optimise_function.ipynb 6
df_dem_plus = pd.read_csv(const.output_path+'/df_dem_plus.csv')

# %% ../../nbs/core/05c_optimise_function.ipynb 8
# The real dementia x and y data 

# covariates 
#covar = ['over_65_pc', 'female_pc', 'ALevel_plus_pc', 'white_pc', 'HYP_afflicted_pc', 'DM_afflicted_pc', 'STIA_afflicted_pc', 'GP_LAD_pc']

covar = ['over_65_pc', 
             'female_pc', 
             'ALevel_plus_pc', 
             'white_pc', 
             'GP_LAD_pc']

# Input data 
x = np.array(df_dem_plus[covar].values.reshape(-1,len(covar)))

# Outcome data 
y = np.array(df_dem_plus['DEM_afflicted_pc'].values.reshape(-1,1))

# %% ../../nbs/core/05c_optimise_function.ipynb 10
# This is the function to use for plotting 
def reverse_shift_log_normal_pdf(x, delta, mu, sigma):
    pdf = []
    for i, x_i in enumerate(x):
        if delta[i] < x_i: 
            pdf.append(0)
        else: 
            x_shift = delta[i] - x_i
            norm_const = 1 / ((x_shift) * sigma * np.sqrt(2 * np.pi))
            exp_part = np.exp(-1 * (1 / (2 * sigma ** 2)) * (np.log(np.subtract(x_shift, mu)) ** 2))
            pdf.append(norm_const.squeeze() * exp_part.squeeze())
            
    return np.array(pdf)

def log_norm_mode(mu:int, # mean of the variables log
                  sigma:int): # standard deviation of the variables log
    return np.exp(mu - sigma**2)

# %% ../../nbs/core/05c_optimise_function.ipynb 13
def log_rvs_shift_log_normal(z, # random variable
                             delta, # the shift parameter
                             mu, # mean of the logarithm of z
                             sigma # standard deviation of the logarithm of z
                             ):
    "Returns the logarithm of the reverse, shifted, log normal probability density function."
    pdf = []
    z_shift = np.array(delta - z)
    for i in range(len(z_shift)):
        if z_shift[i]>0: 
            part1 = (1/(2 * sigma ** 2)) * (2 * mu * np.log(z_shift[i]) - (np.log(z_shift[i])) ** 2 - mu ** 2) 
            part2 = np.log(z_shift[i] * sigma * np.sqrt(2 *np.pi))
            pdf.append(part1 - part2)
        else:
            pdf.append(-np.inf) # returns -inf at the points where the log normal is undefined 
    return np.array(pdf)

def neg_loglike(params, # parameters to optimise
                x, # independent variables 
                y # dependent variables 
                ):
    "Returns the negative log likelihood"
    beta_0 = params[0]
    beta = np.array(params[1:-2])
    mu = params[-2]
    sigma = params[-1]

    y_pred = (np.dot(x, beta)).squeeze() + beta_0
    log_likely = log_rvs_shift_log_normal(y.squeeze(), delta=y_pred.squeeze(), mu=mu, sigma=sigma)
    
    return (-1 * np.sum(log_likely)).squeeze()

# %% ../../nbs/core/05c_optimise_function.ipynb 25
# Use scipy's minimize function with the Nelder-Mead algorithm
result = minimize(neg_loglike, x0=params_0, args=(x,y), method = 'Nelder-Mead')

result

# %% ../../nbs/core/05c_optimise_function.ipynb 28
# Extract the MLE from the parameter samples
MLE_params = result.x

MLE_intercept = MLE_params[0]
MLE_beta = MLE_params[1:-2]
MLE_mu = MLE_params[-2]
MLE_sigma = MLE_params[-1]

print("MLE estimates \n--------------\n--------------")
print(f'Intercept:{MLE_intercept}')
print("--------------\nRegression coefficients\n--------------")
for i, var in enumerate(covar):
    print(f'{var}:{MLE_beta[i]}')
print("--------------\nLog normal coefficients\n--------------")
print("Mu:", MLE_mu)
print("Sigma:", MLE_sigma)
