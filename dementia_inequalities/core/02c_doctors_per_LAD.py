# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/core/02c_GP_doctors_per_LAD.ipynb.

# %% auto 0
__all__ = ['df_LAD_GP_pop', 'df_GP_count', 'list_gps', 'list_gps_codes', 'df_LAD_GP_count', 'df_LAD_GP', 'df_GP_contribution',
           'df_QOF_prev', 'df_QOF_dem', 'with_GP_count', 'with_no_GP_count', 'x', 'x_train', 'y_train', 'regr',
           'y_pred', 'test_y_pred', 'resid_std', 'hetero_noise', 'y']

# %% ../../nbs/core/02c_GP_doctors_per_LAD.ipynb 5
import numpy as np
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

from .. import const

from sklearn import linear_model

# %% ../../nbs/core/02c_GP_doctors_per_LAD.ipynb 10
# Load data about intersections of GP catchment areas and LAD
df_LAD_GP_pop = pd.read_csv(const.pre_output_path+'/LAD_GP_area_intersections.csv')

# Loads data of GP counts 
df_GP_count = pd.read_csv(const.data_path+'/GP_practices_dec_23/gp_Count.csv')

# %% ../../nbs/core/02c_GP_doctors_per_LAD.ipynb 12
# reformat 
list_gps = df_LAD_GP_pop['gp_name'].values
list_gps_codes = [item[0:6] for item in list_gps]
df_LAD_GP_pop['GP_code'] = list_gps_codes

# merge 
df_LAD_GP_count = pd.merge(df_LAD_GP_pop, df_GP_count, left_on='GP_code', right_on='Code.1', how='left')

# %% ../../nbs/core/02c_GP_doctors_per_LAD.ipynb 14
df_LAD_GP_count['GP_contribution_to_LAD'] = df_LAD_GP_count['percent_GP_in_LAD']*df_LAD_GP_count['GP Count']

# tidy up the dataframe a bit before saving it 
df_LAD_GP = df_LAD_GP_count[['LAD_name', 'GP_code', 'gp_name', 'intersection_size', 'intersection_pop', 'percent_GP_in_LAD', 'GP Count', 'GP_contribution_to_LAD']]

df_LAD_GP = df_LAD_GP.drop_duplicates()
df_LAD_GP.reset_index(inplace=True, drop=True)

df_LAD_GP.columns = ['LAD_name', 'GP_code', 'GP_name', 'area_intersection', 'pop_intersection', 'percent_GP_in_LAD', 'GP_count_practice', 'GP_contribution_to_LAD']

# %% ../../nbs/core/02c_GP_doctors_per_LAD.ipynb 16
df_LAD_GP = df_LAD_GP.fillna(0)
df_GP_contribution = df_LAD_GP.groupby('LAD_name').sum()
df_GP_contribution.reset_index(inplace=True)
df_GP_contribution = df_GP_contribution[['LAD_name', 'GP_contribution_to_LAD']]

# %% ../../nbs/core/02c_GP_doctors_per_LAD.ipynb 20
df_LAD_GP.to_csv(const.pre_output_path+'/GP_LAD_inter_GP_count.csv', index=False)

# %% ../../nbs/core/02c_GP_doctors_per_LAD.ipynb 22
df_QOF_prev = pd.read_csv(const.data_path+'/QOF_2122_V2/PREVALENCE_2122_V2.csv')

# Only interested in Dementia diagnosis 
df_QOF_dem = df_QOF_prev[df_QOF_prev['GROUP_CODE']=='DEM'].copy()
# Drop columns which are not useful 
df_QOF_dem.drop(labels=['GROUP_CODE', 'PATIENT_LIST_TYPE'], axis=1, inplace=True)
df_QOF_dem.rename(columns={'REGISTER':'DEM_REGISTER'}, inplace=True)

# %% ../../nbs/core/02c_GP_doctors_per_LAD.ipynb 24
df_QOF_dem = pd.merge(df_QOF_dem, df_GP_count[['Code.1', 'GP Count']], left_on='PRACTICE_CODE', right_on='Code.1', how='left')
df_QOF_dem.drop(columns='Code.1', inplace=True)
with_GP_count = df_QOF_dem[df_QOF_dem['GP Count']>0]
with_no_GP_count = df_QOF_dem[~(df_QOF_dem['GP Count']>0)]

# %% ../../nbs/core/02c_GP_doctors_per_LAD.ipynb 26
# Random regression imputation with heteroskedastic error term 

# Remove datapoints where the number of doctors is over 2 deviations away from the mean
#GP_mean = np.mean(with_GP_count['GP Count'].values)
#GP_std = np.std(with_GP_count['GP Count'].values)
#GP_upper_lim = GP_mean + 3*GP_std

#with_GP_no_outliers = with_GP_count[with_GP_count['GP Count']<GP_upper_lim]

# original
x = df_QOF_dem['PRACTICE_LIST_SIZE'].values.reshape(-1,1)

# original
x_train = with_GP_count['PRACTICE_LIST_SIZE'].values.reshape(-1,1)
y_train =  with_GP_count['GP Count'].values.reshape(-1,1)

# fit regression
regr = linear_model.LinearRegression()
regr.fit(x_train, y_train)
y_pred = regr.predict(x_train)

test_y_pred = regr.predict(x)

# calculate std of variance between predicted data and observed data 
resid_std = np.std(np.abs(y_train-y_pred))
# calculate hetero-skedastic noise
np.random.seed(3)
hetero_noise = 0.00005*np.abs(x) * np.random.normal(loc=0, scale=resid_std, size=x.shape)

# the imputed value - regression plus noise
y = test_y_pred + hetero_noise.reshape(-1,1)

# plot 
plt.figure(figsize=(10, 9), dpi=200)
plt.scatter(x_train, y_train, color = 'xkcd:boring green', alpha=0.5)
plt.plot(x_train, y_pred, color='xkcd:deep lilac', linewidth=2)
plt.scatter(x, y, color='xkcd:windows blue', alpha=0.5)
plt.xlabel('GP practice size', fontsize=16)
plt.ylabel('Number of doctors', fontsize=16)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.legend(['training data', 'regression line', 'random imputed data'], loc='lower right', fontsize=16)
plt.savefig(const.figs_path+'/GP_data_imputation.png')

# %% ../../nbs/core/02c_GP_doctors_per_LAD.ipynb 27
# update missing values in dataframe 
df_QOF_dem['GP_count_random_imputed_missing'] = y

df_QOF_dem['GP_count_regression_imputed'] = df_QOF_dem['GP Count']
df_QOF_dem['GP_count_regression_imputed'].fillna(df_QOF_dem['GP_count_random_imputed_missing'], inplace=True)
df_QOF_dem.drop(columns='GP_count_random_imputed_missing')

# %% ../../nbs/core/02c_GP_doctors_per_LAD.ipynb 30
# load dataset
df_LAD_GP_count = pd.merge(df_LAD_GP_pop, df_QOF_dem[['PRACTICE_CODE', 'GP_count_regression_imputed']], left_on='GP_code', right_on='PRACTICE_CODE', how='right')
df_LAD_GP_count['GP_contribution_to_LAD'] = df_LAD_GP_count['percent_GP_in_LAD']*df_LAD_GP_count['GP_count_regression_imputed']

# tidy up the dataframe a bit before saving it 
df_LAD_GP = df_LAD_GP_count[['LAD_name', 'GP_code', 'gp_name', 'intersection_size', 'intersection_pop', 'percent_GP_in_LAD', 'GP_count_regression_imputed', 'GP_contribution_to_LAD']]
df_LAD_GP.reset_index(inplace=True, drop=True)
df_LAD_GP.columns = ['LAD_name', 'GP_code', 'GP_name', 'area_intersection', 'pop_intersection', 'percent_GP_in_LAD', 'GP_count_practice_imputed', 'GP_contribution_to_LAD']
